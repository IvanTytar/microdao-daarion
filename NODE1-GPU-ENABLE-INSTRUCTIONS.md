# üöÄ –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó: –£–≤—ñ–º–∫–Ω–µ–Ω–Ω—è GPU –¥–ª—è Ollama –Ω–∞ –ù–û–î–ê1

**–î–∞—Ç–∞:** 2025-01-27  
**GPU:** NVIDIA RTX 4000 SFF Ada Generation (20GB VRAM)  
**–ü—Ä–æ–±–ª–µ–º–∞:** Ollama –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î CPU (1583% CPU) –∑–∞–º—ñ—Å—Ç—å GPU  
**–†—ñ—à–µ–Ω–Ω—è:** –£–≤—ñ–º–∫–Ω—É—Ç–∏ GPU acceleration –¥–ª—è Ollama

---

## üìã –ö—Ä–æ–∫ 1: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–æ—Ç–æ—á–Ω–æ–≥–æ —Å—Ç–∞–Ω—É

```bash
# –ù–∞ –ù–û–î–ê1 (144.76.224.179)
ssh root@144.76.224.179

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ GPU
nvidia-smi

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker ps | grep ollama
docker inspect ollama --format '{{.HostConfig.DeviceRequests}}'
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** `[]` (GPU –Ω–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ)

---

## üîß –ö—Ä–æ–∫ 2: –û–Ω–æ–≤–∏—Ç–∏ docker-compose.yml

–ó–Ω–∞–π—Ç–∏ —Ñ–∞–π–ª `docker-compose.yml` –Ω–∞ –ù–û–î–ê1:
```bash
cd /opt/microdao-daarion
ls -la docker-compose.yml
```

–ó–Ω–∞–π—Ç–∏ —Å–µ–∫—Ü—ñ—é `ollama:` —Ç–∞ –¥–æ–¥–∞—Ç–∏ GPU –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é:

```yaml
services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    # –î–û–î–ê–¢–ò GPU –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Æ:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    restart: unless-stopped
```

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ (—è–∫—â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è docker run):**
```bash
docker stop ollama
docker rm ollama
docker run -d \
  --name ollama \
  --gpus all \
  -p 11434:11434 \
  -v ollama-data:/root/.ollama \
  -e NVIDIA_VISIBLE_DEVICES=all \
  ollama/ollama:latest
```

---

## üîÑ –ö—Ä–æ–∫ 3: –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–∏ Ollama

```bash
cd /opt/microdao-daarion

# –ó—É–ø–∏–Ω–∏—Ç–∏ Ollama
docker compose stop ollama

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–∏ –∑ –Ω–æ–≤–æ—é –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é
docker compose up -d ollama

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Å—Ç–∞—Ç—É—Å
docker ps | grep ollama
```

---

## ‚úÖ –ö—Ä–æ–∫ 4: –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU

```bash
# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ GPU utilization
nvidia-smi

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ Ollama —á–µ—Ä–µ–∑ API
curl http://localhost:11434/api/ps

# –ü—Ä–æ—Ç–µ—Å—Ç—É–≤–∞—Ç–∏ Ollama –∑ GPU
docker exec ollama ollama run qwen3:8b "–ü—Ä–∏–≤—ñ—Ç, —Ç–µ—Å—Ç GPU"
```

**–û—á—ñ–∫—É–≤–∞–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
- `nvidia-smi` –ø–æ–∫–∞–∑—É—î –ø—Ä–æ—Ü–µ—Å Ollama –Ω–∞ GPU
- GPU utilization: 30-50%
- CPU –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Ollama: –∑–Ω–∏–∑–∏—Ç—å—Å—è –∑ 1583% –¥–æ 50-100%

---

## üìä –ö—Ä–æ–∫ 5: –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤

```bash
# CPU –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (–º–∞—î –∑–Ω–∏–∑–∏—Ç–∏—Å—è)
top -bn1 | grep "Cpu(s)"

# GPU –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è (–º–∞—î –∑–±—ñ–ª—å—à–∏—Ç–∏—Å—è)
nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv

# Ollama –ø—Ä–æ—Ü–µ—Å–∏
docker exec ollama ollama ps
```

**–û—á—ñ–∫—É–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
- ‚úÖ CPU: 85.3% ‚Üí 40-50% (-35-45%)
- ‚úÖ GPU: 0% ‚Üí 30-50% utilization
- ‚úÖ Ollama CPU: 1583% ‚Üí 50-100%
- ‚úÖ –®–≤–∏–¥–∫—ñ—Å—Ç—å —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å—É: +200-300%

---

## üîç –ö—Ä–æ–∫ 6: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–æ–º–∏–ª–æ–∫

–Ø–∫—â–æ GPU –Ω–µ –ø—Ä–∞—Ü—é—î:

```bash
# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ª–æ–≥–∏ Ollama
docker logs ollama | tail -50

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ nvidia-container-toolkit
nvidia-container-cli --version

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ Docker GPU –ø—ñ–¥—Ç—Ä–∏–º–∫—É
docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
```

**–ú–æ–∂–ª–∏–≤—ñ –ø—Ä–æ–±–ª–µ–º–∏:**
1. ‚ùå `nvidia-container-toolkit` –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
   ```bash
   # –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ nvidia-container-toolkit
   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
   curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
   curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
   sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
   sudo systemctl restart docker
   ```

2. ‚ùå Docker –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î `--gpus`
   ```bash
   # –û–Ω–æ–≤–∏—Ç–∏ Docker –¥–æ –≤–µ—Ä—Å—ñ—ó –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é GPU
   docker --version
   # –ü–æ—Ç—Ä—ñ–±–Ω–∞ –≤–µ—Ä—Å—ñ—è 19.03+
   ```

---

## üìù –ü—Ä–∏–∫–ª–∞–¥ –æ–Ω–æ–≤–ª–µ–Ω–æ–≥–æ docker-compose.yml

```yaml
services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - OLLAMA_NUM_GPU=1
      - OLLAMA_GPU_LAYERS=35  # –î–ª—è qwen3:8b
    restart: unless-stopped
    networks:
      - dagi-network

volumes:
  ollama-data:
    driver: local
```

---

## üéØ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç (–æ–¥–Ω–∞ –∫–æ–º–∞–Ω–¥–∞)

```bash
# –ù–∞ –ù–û–î–ê1
cd /opt/microdao-daarion && \
docker compose stop ollama && \
# –û–Ω–æ–≤–∏—Ç–∏ docker-compose.yml –≤—Ä—É—á–Ω—É, –ø–æ—Ç—ñ–º:
docker compose up -d ollama && \
sleep 5 && \
nvidia-smi && \
docker exec ollama ollama ps
```

---

**Last Updated:** 2025-01-27  
**Status:** üìã –ì–æ—Ç–æ–≤–æ –¥–æ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è




