#!/bin/bash
# –°–∫—Ä–∏–ø—Ç –¥–ª—è —É–≤—ñ–º–∫–Ω–µ–Ω–Ω—è GPU acceleration –¥–ª—è Ollama –Ω–∞ –ù–û–î–ê1
# GPU: NVIDIA RTX 4000 SFF Ada Generation (20GB VRAM)

set -e

echo "üöÄ –£–≤—ñ–º–∫–Ω–µ–Ω–Ω—è GPU acceleration –¥–ª—è Ollama –Ω–∞ –ù–û–î–ê1"
echo "GPU: NVIDIA RTX 4000 SFF Ada Generation (20GB VRAM)"
echo ""

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ GPU
echo "üìä –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ GPU..."
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
echo ""
echo "üîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞..."
OLLAMA_CONTAINER=$(docker ps --format '{{.Names}}' | grep -i ollama | head -1)

if [ -z "$OLLAMA_CONTAINER" ]; then
    echo "‚ùå Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!"
    echo "   –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —á–∏ –∑–∞–ø—É—â–µ–Ω–∏–π Ollama: docker ps | grep ollama"
    exit 1
fi

echo "‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: $OLLAMA_CONTAINER"

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ –≤–∂–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ GPU
echo ""
echo "üîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–æ—Ç–æ—á–Ω–æ—ó –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó GPU..."
GPU_CONFIG=$(docker inspect "$OLLAMA_CONTAINER" --format '{{.HostConfig.DeviceRequests}}' 2>&1)

if echo "$GPU_CONFIG" | grep -q "nvidia"; then
    echo "‚ö†Ô∏è  GPU –≤–∂–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ, –∞–ª–µ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è..."
else
    echo "‚ùå GPU –Ω–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ –¥–ª—è Ollama!"
    echo ""
    echo "üìù –î–ª—è —É–≤—ñ–º–∫–Ω–µ–Ω–Ω—è GPU –ø–æ—Ç—Ä—ñ–±–Ω–æ:"
    echo "   1. –ó—É–ø–∏–Ω–∏—Ç–∏ Ollama: docker stop $OLLAMA_CONTAINER"
    echo "   2. –û–Ω–æ–≤–∏—Ç–∏ docker-compose.yml –∑ GPU –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é"
    echo "   3. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–∏: docker compose up -d ollama"
    echo ""
    echo "üí° –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ docker run –∑ --gpus all"
fi

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU Ollama
echo ""
echo "üìä –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU Ollama..."
nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ Ollama —á–µ—Ä–µ–∑ API
echo ""
echo "üîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ Ollama —á–µ—Ä–µ–∑ API..."
OLLAMA_PS=$(curl -s http://localhost:11434/api/ps 2>&1 || echo "[]")

if echo "$OLLAMA_PS" | grep -q "qwen"; then
    echo "‚úÖ Ollama –º–∞—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –º–æ–¥–µ–ª—ñ"
    echo "$OLLAMA_PS" | python3 -m json.tool 2>/dev/null || echo "$OLLAMA_PS"
else
    echo "‚ö†Ô∏è  Ollama –Ω–µ –º–∞—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"
fi

echo ""
echo "‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"
echo ""
echo "üìã –ù–∞—Å—Ç—É–ø–Ω—ñ –∫—Ä–æ–∫–∏:"
echo "   1. –û–Ω–æ–≤–∏—Ç–∏ docker-compose.yml –¥–ª—è Ollama –∑ GPU"
echo "   2. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–∏ Ollama –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä"
echo "   3. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU: nvidia-smi"
echo "   4. –ü—Ä–æ—Ç–µ—Å—Ç—É–≤–∞—Ç–∏ Ollama –∑ GPU: ollama run qwen3:8b 'test'"




