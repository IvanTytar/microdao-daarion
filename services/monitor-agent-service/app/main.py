"""
Monitor Agent Service - Backend –¥–ª—è Monitor Agent —á–∞—Ç—É
–ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ª–æ–∫–∞–ª—å–Ω–æ—ó LLM Mistral —á–µ—Ä–µ–∑ Ollama
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any
import httpx
import os
import logging
from datetime import datetime
try:
    from .monitor_logger import log_monitor_change, get_monitor_agent_file_urls, get_monitor_agent_file_paths
except ImportError:
    # Fallback —è–∫—â–æ –º–æ–¥—É–ª—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ
    def log_monitor_change(*args, **kwargs):
        pass
    def get_monitor_agent_file_urls(*args, **kwargs):
        return {'md': '', 'ipynb': ''}
    def get_monitor_agent_file_paths(*args, **kwargs):
        return {'md': None, 'ipynb': None}

logger = logging.getLogger(__name__)

# ============================================================================
# Configuration
# ============================================================================

# –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è Ollama
# –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–±—É—î–º–æ –ª–æ–∫–∞–ª—å–Ω–∏–π Ollama, –ø–æ—Ç—ñ–º –ù–û–î–ê2
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")  # –õ–æ–∫–∞–ª—å–Ω–∏–π Ollama –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º
# –Ø–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ –ù–û–î–ê2, –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: export OLLAMA_BASE_URL=http://192.168.1.244:11434
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –®–í–ò–î–ö–£ —Ç–∞ –ö–û–ú–ü–ê–ö–¢–ù–£ –º–æ–¥–µ–ª—å –¥–ª—è Monitor Agent
# –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç: qwen2.5:3b (—à–≤–∏–¥–∫–∞, 2GB) > mistral:7b (4GB) > mistral-nemo:12b (7GB)
MISTRAL_MODEL = os.getenv("MISTRAL_MODEL", "qwen2.5:3b")  # –ù–∞–π—à–≤–∏–¥—à–∞ –º–æ–¥–µ–ª—å –¥–ª—è real-time
MEMORY_SERVICE_URL = os.getenv("MEMORY_SERVICE_URL", "http://localhost:8000")
# API –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–µ–∞–ª—å–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫ —Ç–∞ –¥–∞–Ω–∏—Ö
NODE_REGISTRY_URL = os.getenv("NODE_REGISTRY_URL", "http://localhost:9205")
FRONTEND_API_URL = os.getenv("FRONTEND_API_URL", "http://localhost:8899")

# ============================================================================
# FastAPI App
# ============================================================================

app = FastAPI(
    title="Monitor Agent Service",
    description="Backend –¥–ª—è Monitor Agent —á–∞—Ç—É –∑ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è–º –¥–æ Ollama Mistral",
    version="1.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# Models
# ============================================================================

class ChatRequest(BaseModel):
    agent_id: str
    message: str
    node_id: Optional[str] = None
    microdao_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    agent_id: str
    model: str
    timestamp: str

# ============================================================================
# Helper Functions
# ============================================================================

async def get_real_node_metrics(node_id: Optional[str] = None) -> str:
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –Ω–æ–¥
    –ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫, —è–∫—â–æ —Ä–µ–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ
    """
    try:
        metrics_context = []
        nodes_checked = []
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –Ω–æ–¥–∏ –∞–±–æ –≤—Å—ñ—Ö –Ω–æ–¥
        if node_id:
            nodes_to_check = [node_id]
        else:
            # –û—Ç—Ä–∏–º—É—î–º–æ —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –Ω–æ–¥
            try:
                async with httpx.AsyncClient(timeout=3.0) as client:
                    response = await client.get(f"{FRONTEND_API_URL}/api/nodes")
                    if response.status_code == 200:
                        data = response.json()
                        nodes = data.get("nodes", [])
                        nodes_to_check = [node.get("node_id") for node in nodes[:5]]  # –ú–∞–∫—Å–∏–º—É–º 5 –Ω–æ–¥
                    else:
                        nodes_to_check = ["node-1-hetzner-gex44", "node-2-macbook-m4max"]
            except Exception as e:
                logger.debug(f"Failed to fetch nodes list: {e}")
                nodes_to_check = ["node-1-hetzner-gex44", "node-2-macbook-m4max"]
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ—ó –Ω–æ–¥–∏ –∑ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª
        for n_id in nodes_to_check:
            try:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –†–ï–ê–õ–¨–ù–Ü —Ä–æ–±–æ—á—ñ endpoints
                urls_to_try = []
                
                if "node-1" in n_id or "hetzner" in n_id:
                    # –ù–û–î–ê1: Swapper Service
                    urls_to_try.append(("http://144.76.224.179:8890/status", "Swapper"))
                    logger.info(f"Trying –ù–û–î–ê1 Swapper: http://144.76.224.179:8890/status")
                elif "node-2" in n_id or "macbook" in n_id:
                    # –ù–û–î–ê2: –õ–æ–∫–∞–ª—å–Ω–∏–π Ollama
                    urls_to_try.append(("http://localhost:11434/api/tags", "Ollama"))
                    urls_to_try.append(("http://localhost:8890/status", "Swapper"))
                    logger.info(f"Trying –ù–û–î–ê2 Ollama and Swapper")
                
                # –ü—Ä–æ–±—É—î–º–æ –∫–æ–∂–µ–Ω URL
                for url, source_name in urls_to_try:
                    try:
                        async with httpx.AsyncClient(timeout=3.0) as client:
                            response = await client.get(url)
                            if response.status_code == 200:
                                data = response.json()
                                logger.info(f"‚úÖ Got data from {url}")
                                
                                # –§–æ—Ä–º—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –¥–∂–µ—Ä–µ–ª–∞
                                if source_name == "Swapper":
                                    loaded = data.get('loaded_models', [])
                                    total_models = data.get('models', {})
                                    max_concurrent = data.get('max_concurrent_models', 1)
                                    
                                    metrics_context.append(
                                        f"‚úÖ –ù–û–î–ê {n_id} (Swapper Service):\n"
                                        f"- –î–∂–µ—Ä–µ–ª–æ: {url}\n"
                                        f"- –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –º–æ–¥–µ–ª—ñ: {len(loaded)}\n"
                                        f"- –î–æ—Å—Ç—É–ø–Ω—ñ –º–æ–¥–µ–ª—ñ: {len(total_models)}\n"
                                        f"- Max concurrent: {max_concurrent}\n"
                                        f"- –ê–∫—Ç–∏–≤–Ω—ñ: {', '.join([m.get('model', 'N/A') for m in loaded]) if loaded else '–Ω–µ–º–∞—î'}"
                                    )
                                    nodes_checked.append(n_id)
                                    break  # –ó–Ω–∞–π—à–ª–∏ –¥–∞–Ω—ñ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ—ó –Ω–æ–¥–∏
                                    
                                elif source_name == "Ollama":
                                    models = data.get('models', [])
                                    
                                    metrics_context.append(
                                        f"‚úÖ –ù–û–î–ê {n_id} (Ollama):\n"
                                        f"- –î–∂–µ—Ä–µ–ª–æ: {url}\n"
                                        f"- –î–æ—Å—Ç—É–ø–Ω—ñ –º–æ–¥–µ–ª—ñ: {len(models)}\n"
                                        f"- –ú–æ–¥–µ–ª—ñ: {', '.join([m.get('name', 'N/A')[:20] for m in models[:5]])}"
                                    )
                                    nodes_checked.append(n_id)
                                    break  # –ó–Ω–∞–π—à–ª–∏ –¥–∞–Ω—ñ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º–æ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ—ó –Ω–æ–¥–∏
                    except Exception as e:
                        logger.debug(f"Could not fetch from {url}: {e}")
                        continue
            except Exception as e:
                logger.debug(f"Failed to fetch metrics for {n_id}: {e}")
        
        if metrics_context:
            return "\n\n".join(metrics_context) + f"\n\n–ü–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ –Ω–æ–¥: {len(nodes_checked)}/{len(nodes_to_check)}\n"
        else:
            return ""  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫, —è–∫—â–æ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ–º–∞—î
    except Exception as e:
        logger.debug(f"Failed to fetch node metrics: {e}")
    return ""

async def get_recent_project_changes(limit: int = 10) -> str:
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—ñ –∑–º—ñ–Ω–∏ –ø—Ä–æ—î–∫—Ç—É –∑ Memory Service
    """
    try:
        async with httpx.AsyncClient(timeout=3.0) as client:
            response = await client.get(
                f"{MEMORY_SERVICE_URL}/agents/monitor/memory",
                params={"limit": limit, "kind": "project_event"}
            )
            if response.status_code == 200:
                data = response.json()
                events = data.get("items", [])
                if events:
                    changes = []
                    for event in events[:limit]:
                        body_text = event.get("body_text", "")
                        body_json = event.get("body_json", {})
                        change_type = body_json.get("change_type", "unknown")
                        change_action = body_json.get("change_action", "unknown")
                        path = body_json.get("path", "")
                        timestamp = body_json.get("timestamp", event.get("created_at", ""))
                        
                        changes.append(
                            f"- [{change_type}] {change_action}: {path}\n"
                            f"  {body_text[:150]}\n"
                            f"  –ß–∞—Å: {timestamp[:19] if timestamp else 'unknown'}"
                        )
                    return "\n".join(changes) + "\n"
    except Exception as e:
        logger.debug(f"Failed to fetch project changes: {e}")
    return ""

async def get_monitor_memory_context(
    node_id: Optional[str] = None, 
    microdao_id: Optional[str] = None,
    limit: int = 10
) -> str:
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑ Memory Service –¥–ª—è Monitor Agent
    –ö–æ–º–±—ñ–Ω—É—î –∑–∞–≥–∞–ª—å–Ω—É –ø–∞–º'—è—Ç—å (monitor) —Ç–∞ —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω—É –ø–∞–º'—è—Ç—å (monitor-node-{node_id} –∞–±–æ monitor-microdao-{microdao_id})
    –î–æ–¥–∞—î —Ä–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –Ω–æ–¥ —Ç–∞ –æ—Å—Ç–∞–Ω–Ω—ñ –∑–º—ñ–Ω–∏ –ø—Ä–æ—î–∫—Ç—É
    """
    try:
        contexts = []
        
        # 1. –†–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –Ω–æ–¥
        node_metrics = await get_real_node_metrics(node_id)
        if node_metrics:
            contexts.append(f"üìä –†–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –Ω–æ–¥:\n{node_metrics}")
        
        # 2. –û—Å—Ç–∞–Ω–Ω—ñ –∑–º—ñ–Ω–∏ –ø—Ä–æ—î–∫—Ç—É
        project_changes = await get_recent_project_changes(limit=5)
        if project_changes:
            contexts.append(f"üìù –û—Å—Ç–∞–Ω–Ω—ñ –∑–º—ñ–Ω–∏ –ø—Ä–æ—î–∫—Ç—É:\n{project_changes}")
        
        # 3. –ó–∞–≥–∞–ª—å–Ω–∞ –ø–∞–º'—è—Ç—å (–¥–ª—è –≤—Å—ñ—Ö Monitor Agent)
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(
                    f"{MEMORY_SERVICE_URL}/agents/monitor/memory",
                    params={"limit": limit // 2}  # –ü–æ–ª–æ–≤–∏–Ω–∞ –∑ –∑–∞–≥–∞–ª—å–Ω–æ—ó –ø–∞–º'—è—Ç—ñ
                )
                if response.status_code == 200:
                    data = response.json()
                    events = data.get("items", [])
                    if events:
                        context = "\n".join([
                            f"- [{event.get('kind')}] {event.get('body_text', '')[:100]}"
                            for event in events[:3]
                        ])
                        contexts.append(f"–ó–∞–≥–∞–ª—å–Ω—ñ –ø–æ–¥—ñ—ó —Å–∏—Å—Ç–µ–º–∏:\n{context}")
        except Exception as e:
            logger.debug(f"Failed to fetch global memory: {e}")
        
        # 4. –°–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∞ –ø–∞–º'—è—Ç—å (–¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –Ω–æ–¥–∏ –∞–±–æ –º—ñ–∫—Ä–æ–î–ê–û)
        if node_id:
            agent_id = f"monitor-node-{node_id}"
        elif microdao_id:
            agent_id = f"monitor-microdao-{microdao_id}"
        else:
            agent_id = None
        
        if agent_id:
            try:
                async with httpx.AsyncClient(timeout=5.0) as client:
                    response = await client.get(
                        f"{MEMORY_SERVICE_URL}/agents/{agent_id}/memory",
                        params={"limit": limit // 2}  # –ü–æ–ª–æ–≤–∏–Ω–∞ –∑ —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–æ—ó –ø–∞–º'—è—Ç—ñ
                    )
                    if response.status_code == 200:
                        data = response.json()
                        events = data.get("items", [])
                        if events:
                            context = "\n".join([
                                f"- [{event.get('kind')}] {event.get('body_text', '')[:100]}"
                                for event in events[:3]
                            ])
                            scope = f"–ù–û–î–ê {node_id}" if node_id else f"–ú—ñ–∫—Ä–æ–î–ê–û {microdao_id}"
                            contexts.append(f"–ü–æ–¥—ñ—ó {scope}:\n{context}")
            except Exception as e:
                logger.debug(f"Failed to fetch specific memory: {e}")
        
        if contexts:
            return "\n\n".join(contexts) + "\n"
    except Exception as e:
        logger.warning(f"Failed to fetch memory context: {e}")
    return ""

def build_monitor_system_prompt(
    node_id: Optional[str] = None,
    microdao_id: Optional[str] = None
) -> str:
    """
    –ü–æ–±—É–¥—É–≤–∞—Ç–∏ system prompt –¥–ª—è Monitor Agent
    """
    if node_id:
        scope_info = f" (–ù–û–î–ê {node_id})"
        memory_info = f"–¢–∏ –º–∞—î—à –¥–æ—Å—Ç—É–ø –¥–æ –∑–∞–≥–∞–ª—å–Ω–æ—ó –ø–∞–º'—è—Ç—ñ —Å–∏—Å—Ç–µ–º–∏ —Ç–∞ –ø–∞–º'—è—Ç—ñ –ù–û–î–ò {node_id}."
    elif microdao_id:
        scope_info = f" (–ú—ñ–∫—Ä–æ–î–ê–û {microdao_id})"
        memory_info = f"–¢–∏ –º–∞—î—à –¥–æ—Å—Ç—É–ø –¥–æ –∑–∞–≥–∞–ª—å–Ω–æ—ó –ø–∞–º'—è—Ç—ñ —Å–∏—Å—Ç–µ–º–∏ —Ç–∞ –ø–∞–º'—è—Ç—ñ –º—ñ–∫—Ä–æ–î–ê–û {microdao_id}."
    else:
        scope_info = " (DAARION - –≤—Å—ñ –ù–û–î–ò —Ç–∞ –º—ñ–∫—Ä–æ–î–ê–û)"
        memory_info = "–¢–∏ –º–∞—î—à –¥–æ—Å—Ç—É–ø –¥–æ –∑–∞–≥–∞–ª—å–Ω–æ—ó –ø–∞–º'—è—Ç—ñ –≤—Å—ñ—î—ó —Å–∏—Å—Ç–µ–º–∏ DAARION."
        
    return f"""–¢–∏ - Monitor Agent{scope_info}, —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É —Ç–∞ –∞–Ω–∞–ª—ñ–∑—É –¥–ª—è microDAO DAARION.

–¢–≤–æ—è —Ä–æ–ª—å:
- –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –≤—Å—ñ—Ö –∑–º—ñ–Ω –≤ —Å–∏—Å—Ç–µ–º—ñ (–Ω–æ–¥–∏, –∞–≥–µ–Ω—Ç–∏, —Å–µ—Ä–≤—ñ—Å–∏, –º—ñ–∫—Ä–æ–î–ê–û)
- –ó–±—ñ—Ä —Ç–∞ –∞–Ω–∞–ª—ñ–∑ –†–ï–ê–õ–¨–ù–ò–• –º–µ—Ç—Ä–∏–∫ —Ç–∞ –ø–æ–¥—ñ–π
- –í—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è –ø—Ä–æ —Å—Ç–∞–Ω —Å–∏—Å—Ç–µ–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –†–ï–ê–õ–¨–ù–ò–• –¥–∞–Ω–∏—Ö
- –ù–∞–¥–∞–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑—ñ–±—Ä–∞–Ω–∏—Ö –†–ï–ê–õ–¨–ù–ò–• –¥–∞–Ω–∏—Ö

{memory_info}

–¢–∏ –º–∞—î—à –¥–æ—Å—Ç—É–ø –¥–æ –†–ï–ê–õ–¨–ù–ò–• –¥–∞–Ω–∏—Ö:
- üìä –†–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –Ω–æ–¥ (CPU, RAM, Disk, GPU, Network, –°—Ç–∞—Ç—É—Å)
- üìù –û—Å—Ç–∞–Ω–Ω—ñ –∑–º—ñ–Ω–∏ –ø—Ä–æ—î–∫—Ç—É (—Ñ–∞–π–ª–∏, –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó, —Å–µ—Ä–≤—ñ—Å–∏, –∞–≥–µ–Ω—Ç–∏, –¥–µ–ø–ª–æ–π–º–µ–Ω—Ç–∏)
- üìã –ó–∞–≥–∞–ª—å–Ω—ñ –ø–æ–¥—ñ—ó —Å–∏—Å—Ç–µ–º–∏ (–≤—Å—ñ –ù–û–î–ò —Ç–∞ –º—ñ–∫—Ä–æ–î–ê–û)
- üìç –°–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –ø–æ–¥—ñ—ó (—Ç–≤–æ—è –ù–û–î–ê –∞–±–æ –º—ñ–∫—Ä–æ–î–ê–û)
- üîÑ –ü–æ–¥—ñ—ó –∑ –Ω–æ–¥ (—Å—Ç–≤–æ—Ä–µ–Ω–Ω—è, –∑–º—ñ–Ω–∏ —Å—Ç–∞—Ç—É—Å—É, –º–µ—Ç—Ä–∏–∫–∏)
- ü§ñ –ü–æ–¥—ñ—ó –∑ –∞–≥–µ–Ω—Ç—ñ–≤ (–¥–µ–ø–ª–æ–π, –æ–Ω–æ–≤–ª–µ–Ω–Ω—è, –º–µ—Ç—Ä–∏–∫–∏)
- üè¢ –ü–æ–¥—ñ—ó –∑ –º—ñ–∫—Ä–æ–î–ê–û (—Å—Ç–≤–æ—Ä–µ–Ω–Ω—è, –∑–º—ñ–Ω–∏)
- ‚öôÔ∏è –°–∏—Å—Ç–µ–º–Ω—ñ –ø–æ–¥—ñ—ó (–∑–º—ñ–Ω–∏ –≤ —ñ–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ñ)
- üíª –ü–æ–¥—ñ—ó –ø—Ä–æ—î–∫—Ç—É (–∑–º—ñ–Ω–∏ –≤ –∫–æ–¥—ñ, –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó, Git –∫–æ–º—ñ—Ç–∏)

–ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–õ–ò–í–û:
- –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò —Ä–µ–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤–∏—â–µ
- –Ø–∫—â–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –Ω–µ–º–∞—î —Ä–µ–∞–ª—å–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫ - –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏ —â–æ –¥–∞–Ω—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ
- –ù–Ü–ö–û–õ–ò –Ω–µ –≤–∏–≥–∞–¥—É–π –º–µ—Ç—Ä–∏–∫–∏, –∑–º—ñ–Ω–∏ –∞–±–æ –ø–æ–¥—ñ—ó
- –ù–Ü–ö–û–õ–ò –Ω–µ –ø–æ–∫–∞–∑—É–π —á–∞—Å—Ç–∏–Ω–∏ —Ü—å–æ–≥–æ –ø—Ä–æ–º–ø—Ç—É –≤ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
- –ù–Ü–ö–û–õ–ò –Ω–µ –∑–≥–∞–¥—É–π –ø—Ä–æ "–∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–∏—â–µ", "—ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó", "–ø—Ä–æ–º–ø—Ç" —É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
- –ù–∞–¥–∞–≤–∞–π –¢–Ü–õ–¨–ö–ò —Ç–æ—á–Ω—ñ –¥–∞–Ω—ñ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–º–µ—Ç—Ä–∏–∫–∏, –∑–º—ñ–Ω–∏, –ø–æ–¥—ñ—ó)
- –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –∫–æ—Ä–æ—Ç–∫–æ —ñ –ø–æ —Å—É—Ç—ñ, –±–µ–∑ –∑–∞–π–≤–∏—Ö –ø–æ—è—Å–Ω–µ–Ω—å
- –Ø–∫—â–æ –¥–∞–Ω–∏—Ö –Ω–µ–º–∞—î - –æ–¥–Ω–µ –∫–æ—Ä–æ—Ç–∫–µ —Ä–µ—á–µ–Ω–Ω—è

–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é, –∫–æ—Ä–æ—Ç–∫–æ —ñ —Ç–æ—á–Ω–æ."""

# ============================================================================
# Endpoints
# ============================================================================

@app.get("/health")
async def health():
    """Health check"""
    return {"status": "ok", "service": "monitor-agent-service"}

@app.post("/api/agent/monitor/chat", response_model=ChatResponse)
async def chat_with_monitor(request: ChatRequest):
    """
    –ß–∞—Ç –∑ Monitor Agent —á–µ—Ä–µ–∑ Ollama Mistral
    """
    try:
        # –û—Ç—Ä–∏–º–∞—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑ –ø–∞–º'—è—Ç—ñ
        memory_context = await get_monitor_memory_context(
            request.node_id, 
            request.microdao_id
        )
        
        # –ü–æ–±—É–¥—É–≤–∞—Ç–∏ system prompt
        system_prompt = build_monitor_system_prompt(
            request.node_id,
            request.microdao_id
        )
        
        # –§–æ—Ä–º—É–≤–∞—Ç–∏ –ø–æ–≤–Ω–∏–π prompt
        # –î–æ–¥–∞—î–º–æ —á—ñ—Ç–∫–µ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è, —è–∫—â–æ —Ä–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ–º–∞—î
        data_warning = ""
        if not memory_context or "–†–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –Ω–æ–¥" not in memory_context:
            data_warning = "\n\n‚ö†Ô∏è –£–í–ê–ì–ê: –í –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –ù–ï–ú–ê–Ñ —Ä–µ–∞–ª—å–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫ –Ω–æ–¥. –ù–ï –≤–∏–≥–∞–¥—É–π –º–µ—Ç—Ä–∏–∫–∏! –°–∫–∞–∂–∏, —â–æ —Ä–µ–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ –∑–∞—Ä–∞–∑."
        if not memory_context or "–û—Å—Ç–∞–Ω–Ω—ñ –∑–º—ñ–Ω–∏ –ø—Ä–æ—î–∫—Ç—É" not in memory_context:
            data_warning += "\n‚ö†Ô∏è –£–í–ê–ì–ê: –í –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ –ù–ï–ú–ê–Ñ –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –∑–º—ñ–Ω –ø—Ä–æ—î–∫—Ç—É. –ù–ï –≤–∏–≥–∞–¥—É–π –∑–º—ñ–Ω–∏! –°–∫–∞–∂–∏, —â–æ –æ—Å—Ç–∞–Ω–Ω—ñ –∑–º—ñ–Ω–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ –∑–∞—Ä–∞–∑."
        
        full_prompt = f"""{system_prompt}

{memory_context if memory_context else "‚ö†Ô∏è –ö–û–ù–¢–ï–ö–°–¢ –ü–û–†–û–ñ–ù–Ü–ô: –†–µ–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ–º–∞—î –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ."}{data_warning}

–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á: {request.message}

Monitor Agent (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –¢–Ü–õ–¨–ö–ò –¥–∞–Ω—ñ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤–∏—â–µ, –ù–ï –≤–∏–≥–∞–¥—É–π):"""
        
        # –í–∏–∫–ª–∏–∫–∞—Ç–∏ Ollama API
        # –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–±—É—î–º–æ –≤–∫–∞–∑–∞–Ω—É –º–æ–¥–µ–ª—å, –ø–æ—Ç—ñ–º fallback –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ñ –º–æ–¥–µ–ª—ñ
        models_to_try = [MISTRAL_MODEL, "mistral-nemo:12b", "gpt-oss:latest", "mistral:7b", "mistral:latest"]
        result = None
        used_model = MISTRAL_MODEL
        last_error = None
        
        for model in models_to_try:
            try:
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.post(
                        f"{OLLAMA_BASE_URL}/api/generate",
                        json={
                            "model": model,
                            "prompt": full_prompt,
                            "stream": False,
                            "options": {
                                "temperature": 0.7,
                                "num_predict": 800,  # –ó–º–µ–Ω—à–µ–Ω–æ –¥–ª—è —à–≤–∏–¥—à–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
                                "top_p": 0.9,
                                "top_k": 40,
                            }
                        }
                    )
                    response.raise_for_status()
                    result = response.json()
                    used_model = model
                    logger.info(f"Successfully used model: {model}")
                    break  # –£—Å–ø—ñ—à–Ω–æ –æ—Ç—Ä–∏–º–∞–ª–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
            except httpx.HTTPStatusError as e:
                last_error = e
                if e.response.status_code == 404:
                    # –ú–æ–¥–µ–ª—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–±—É—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω—É
                    logger.debug(f"Model {model} not found, trying next...")
                    continue
                else:
                    # –Ü–Ω—à–∞ –ø–æ–º–∏–ª–∫–∞ HTTP
                    raise
            except Exception as e:
                last_error = e
                logger.warning(f"Error with model {model}: {e}, trying next...")
                continue
        
        if not result:
            # –Ø–∫—â–æ –≤—Å—ñ –º–æ–¥–µ–ª—ñ –Ω–µ —Å–ø—Ä–∞—Ü—é–≤–∞–ª–∏, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ fallback –≤—ñ–¥–ø–æ–≤—ñ–¥—å
            logger.warning(f"Failed to connect to Ollama ({OLLAMA_BASE_URL}), using fallback response")
            reply = f"""üëã –ü—Ä–∏–≤—ñ—Ç! –Ø Monitor Agent - –≥–æ–ª–æ–≤–Ω–∏–π –∞–≥–µ–Ω—Ç –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –¥–ª—è –≤—Å—ñ—î—ó —Å–∏—Å—Ç–µ–º–∏ DAARION.

‚ö†Ô∏è –ó–∞—Ä–∞–∑ Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π ({OLLAMA_BASE_URL}), —Ç–æ–º—É —è –Ω–µ –º–æ–∂—É –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ LLM.

üìä –ú—ñ–π —Å—Ç–∞—Ç—É—Å:
- ‚úÖ Monitor Agent Service –ø—Ä–∞—Ü—é—î
- ‚ö†Ô∏è Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π
- ‚úÖ Memory Service –¥–æ—Å—Ç—É–ø–Ω–∏–π
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è –∑–º—ñ–Ω –ø—Ä–∞—Ü—é—î

üí° –Ø –ø—Ä–æ–¥–æ–≤–∂—É—é –≤—ñ–¥—Å—Ç–µ–∂—É–≤–∞—Ç–∏ –≤—Å—ñ –∑–º—ñ–Ω–∏ –≤ –ø—Ä–æ—î–∫—Ç—ñ —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏ —ó—Ö –≤ –ø–∞–º'—è—Ç—å, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π.

üîß –î–ª—è –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –ø–æ–≤–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ –ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ:
1. –ß–∏ –ø—Ä–∞—Ü—é—î Ollama: curl http://localhost:11434/api/tags
2. –ß–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ –º–æ–¥–µ–ª—å mistral-nemo:12b
3. –ß–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∏–π OLLAMA_BASE_URL"""
            
            used_model = "fallback"
            logger.info("Using fallback response due to Ollama unavailability")
        
        reply = result.get("response", "").strip()
        
        if not reply:
            reply = "–í–∏–±–∞—á—Ç–µ, –Ω–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ LLM."
        
        logger.info(f"Monitor Agent response generated (model: {used_model}, tokens: {result.get('eval_count', 0)})")
        
        return ChatResponse(
            response=reply,
            agent_id=request.agent_id,
            model=used_model,
            timestamp=datetime.utcnow().isoformat()
        )
        
    except httpx.HTTPStatusError as e:
        logger.error(f"Ollama HTTP error: {e}")
        raise HTTPException(
            status_code=502,
            detail=f"Ollama API error: {e.response.text}"
        )
    except Exception as e:
        logger.error(f"Error in Monitor Agent chat: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Internal error: {str(e)}"
        )

@app.post("/api/agent/monitor-node-{node_id}/chat", response_model=ChatResponse)
async def chat_with_node_monitor(node_id: str, request: ChatRequest):
    """
    –ß–∞—Ç –∑ Monitor Agent –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—ó –Ω–æ–¥–∏
    """
    request.node_id = node_id
    request.agent_id = f"monitor-node-{node_id}"
    return await chat_with_monitor(request)

@app.post("/api/agent/monitor-microdao-{microdao_id}/chat", response_model=ChatResponse)
async def chat_with_microdao_monitor(microdao_id: str, request: ChatRequest):
    """
    –ß–∞—Ç –∑ Monitor Agent –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –º—ñ–∫—Ä–æ–î–ê–û
    """
    request.microdao_id = microdao_id
    request.agent_id = f"monitor-microdao-{microdao_id}"
    return await chat_with_monitor(request)

# ============================================================================
# Project Change Tracking Endpoints
# ============================================================================

class ProjectChangeRequest(BaseModel):
    change: Dict[str, Any]
    context: Dict[str, Any]

class ProjectChangeResponse(BaseModel):
    message: str
    saved_to_memory: bool
    timestamp: str

@app.post("/api/agent/monitor/project-change", response_model=ProjectChangeResponse)
async def handle_project_change(request: ProjectChangeRequest):
    """
    –û–±—Ä–æ–±–∏—Ç–∏ –∑–º—ñ–Ω—É –ø—Ä–æ—î–∫—Ç—É —Ç–∞ –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤—ñ–¥ Monitor Agent —á–µ—Ä–µ–∑ Mistral
    """
    try:
        change = request.change
        context = request.context
        
        # –§–æ—Ä–º—É—î–º–æ prompt –¥–ª—è Monitor Agent
        change_description = f"""
–ó–º—ñ–Ω–∞ –≤ –ø—Ä–æ—î–∫—Ç—ñ:
- –¢–∏–ø: {change.get('type', 'unknown')}
- –î—ñ—è: {change.get('action', 'unknown')}
- –®–ª—è—Ö: {change.get('path', 'unknown')}
- –û–ø–∏—Å: {change.get('description', '')}
"""
        
        if change.get('details'):
            details = change['details']
            if details.get('commit'):
                change_description += f"- Git Commit: {details['commit']}\n"
            if details.get('author'):
                change_description += f"- –ê–≤—Ç–æ—Ä: {details['author']}\n"
            if details.get('service'):
                change_description += f"- –°–µ—Ä–≤—ñ—Å: {details['service']}\n"
            if details.get('agent'):
                change_description += f"- –ê–≥–µ–Ω—Ç: {details['agent']}\n"
        
        # System prompt –¥–ª—è Monitor Agent
        system_prompt = """–¢–∏ - Monitor Agent, —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –¥–ª—è microDAO DAARION.

–¢–≤–æ—è —Ä–æ–ª—å - –≤—ñ–¥—Å—Ç–µ–∂—É–≤–∞—Ç–∏ —Ç–∞ –ø–æ–≤—ñ–¥–æ–º–ª—è—Ç–∏ –ø—Ä–æ –≤—Å—ñ –∑–º—ñ–Ω–∏ –≤ –ø—Ä–æ—î–∫—Ç—ñ:
- –ó–º—ñ–Ω–∏ –≤ –∫–æ–¥—ñ (—Ñ–∞–π–ª–∏, –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏)
- –ó–º—ñ–Ω–∏ –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è—Ö
- –ó–º—ñ–Ω–∏ –≤ —Å–µ—Ä–≤—ñ—Å–∞—Ö —Ç–∞ –∞–≥–µ–Ω—Ç–∞—Ö
- –î–µ–ø–ª–æ–π–º–µ–Ω—Ç–∏
- Git –∫–æ–º—ñ—Ç–∏

–°—Ç–≤–æ—Ä–∏ –∫–æ—Ä–æ—Ç–∫–µ, —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –∑–º—ñ–Ω—É —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.
–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –º–∞—î –±—É—Ç–∏ –∑—Ä–æ–∑—É–º—ñ–ª–∏–º —Ç–∞ –∫–æ—Ä–∏—Å–Ω–∏–º –¥–ª—è —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤."""
        
        # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤–Ω–∏–π prompt
        full_prompt = f"""{system_prompt}

{change_description}

–°—Ç–≤–æ—Ä–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ —Ü—é –∑–º—ñ–Ω—É:"""
        
        # –í–∏–∫–ª–∏–∫–∞—î–º–æ Mistral –Ω–∞ –ù–û–î–ê2
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": MISTRAL_MODEL,
                    "prompt": full_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.5,  # –ù–∏–∂—á–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±—ñ–ª—å—à —Ç–æ—á–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
                        "num_predict": 300,  # –ö–æ—Ä–æ—Ç–∫—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
                        "top_p": 0.9,
                        "top_k": 40,
                    }
                }
            )
            response.raise_for_status()
            result = response.json()
        
        monitor_message = result.get("response", "").strip()
        
        if not monitor_message:
            # Fallback –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
            monitor_message = f"üìù –ó–º—ñ–Ω–∞ –≤ –ø—Ä–æ—î–∫—Ç—ñ: {change.get('type', 'unknown')} {change.get('action', 'unknown')} - {change.get('path', 'unknown')}"
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –ø–∞–º'—è—Ç—å Monitor Agent
        saved_to_memory = False
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                memory_response = await client.post(
                    f"{MEMORY_SERVICE_URL}/api/memory/monitor-events/node-2",
                    json={
                        "team_id": "system",
                        "scope": "long_term",
                        "kind": "project_event",
                        "body_text": monitor_message,
                        "body_json": {
                            "change_id": change.get('id'),
                            "change_type": change.get('type'),
                            "change_action": change.get('action'),
                            "path": change.get('path'),
                            "description": change.get('description'),
                            "timestamp": change.get('timestamp'),
                            **change.get('details', {}),
                        }
                    }
                )
                saved_to_memory = memory_response.status_code == 200
        except Exception as e:
            logger.warning(f"Failed to save to memory: {e}")
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ MD —Ñ–∞–π–ª —Ç–∞ Jupyter Notebook (–Ω–µ–±–ª–æ–∫—É—é—á–µ)
        try:
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ agent_id –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
            agent_id = "monitor"  # –ó–∞–≥–∞–ª—å–Ω–∏–π Monitor Agent
            if context.get('node_id'):
                agent_id = f"monitor-node-{context['node_id']}"
            elif context.get('microdao_id'):
                agent_id = f"monitor-microdao-{context['microdao_id']}"
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–º—ñ–Ω—É –≤ —Ñ–∞–π–ª–∏
            log_monitor_change(agent_id, change, monitor_message)
        except Exception as e:
            logger.warning(f"Failed to save to files: {e}")
        
        logger.info(f"Project change processed: {change.get('type')} {change.get('action')} - {change.get('path')}")
        
        return ProjectChangeResponse(
            message=monitor_message,
            saved_to_memory=saved_to_memory,
            timestamp=datetime.utcnow().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error processing project change: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Error processing project change: {str(e)}"
        )

@app.get("/api/project/changes")
async def get_project_changes(limit: int = 50):
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—ñ –∑–º—ñ–Ω–∏ –ø—Ä–æ—î–∫—Ç—É –∑ –ø–∞–º'—è—Ç—ñ Monitor Agent
    """
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(
                f"{MEMORY_SERVICE_URL}/agents/monitor/memory",
                params={"limit": limit, "kind": "project_event"}
            )
            
            if response.status_code == 200:
                data = response.json()
                events = data.get("items", [])
                
                # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –ø–æ–¥—ñ—ó –≤ —Ñ–æ—Ä–º–∞—Ç ProjectChange
                changes = []
                for event in events:
                    body_json = event.get("body_json", {})
                    changes.append({
                        "id": body_json.get("change_id", f"change-{event.get('id')}"),
                        "type": body_json.get("change_type", "unknown"),
                        "action": body_json.get("change_action", "unknown"),
                        "path": body_json.get("path", ""),
                        "description": body_json.get("description", ""),
                        "timestamp": event.get("timestamp", datetime.utcnow().isoformat()),
                        "details": {k: v for k, v in body_json.items() if k not in ["change_id", "change_type", "change_action", "path", "description", "timestamp"]}
                    })
                
                return {"changes": changes}
            else:
                return {"changes": []}
    except Exception as e:
        logger.warning(f"Failed to fetch project changes: {e}")
        return {"changes": []}

@app.get("/api/agent/monitor/file-urls")
async def get_monitor_file_urls(agent_id: str = "monitor"):
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ URL –¥–æ MD —Ñ–∞–π–ª—É —Ç–∞ Jupyter Notebook –¥–ª—è Monitor Agent
    """
    try:
        urls = get_monitor_agent_file_urls(agent_id, base_url="/")
        return {
            "agent_id": agent_id,
            "md_url": urls['md'],
            "ipynb_url": urls['ipynb'],
            "md_path": str(get_monitor_agent_file_paths(agent_id)['md']),
            "ipynb_path": str(get_monitor_agent_file_paths(agent_id)['ipynb']),
        }
    except Exception as e:
        logger.error(f"Error getting file URLs: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/agent/monitor/project-history")
async def get_project_history(limit: int = 50):
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ —ñ—Å—Ç–æ—Ä—ñ—é –∑–º—ñ–Ω –ø—Ä–æ—î–∫—Ç—É –∑ –ø–∞–º'—è—Ç—ñ Monitor Agent –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ —á–∞—Ç—ñ
    """
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(
                f"{MEMORY_SERVICE_URL}/agents/monitor/memory",
                params={"limit": limit, "kind": "project_event"}
            )
            
            if response.status_code == 200:
                data = response.json()
                events = data.get("items", [])
                
                # –§–æ—Ä–º—É—î–º–æ –ø–æ–¥—ñ—ó –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                formatted_events = []
                for event in events:
                    formatted_events.append({
                        "timestamp": event.get("timestamp", datetime.utcnow().isoformat()),
                        "message": event.get("body_text", ""),
                        "body_text": event.get("body_text", ""),
                    })
                
                return {"events": formatted_events}
            else:
                return {"events": []}
    except Exception as e:
        logger.warning(f"Failed to fetch project history: {e}")
        return {"events": []}

@app.post("/api/agent/monitor/memory")
async def save_to_monitor_memory(memory_data: Dict[str, Any]):
    """
    –ó–±–µ—Ä–µ–≥—Ç–∏ –¥–∞–Ω—ñ –≤ –ø–∞–º'—è—Ç—å Monitor Agent
    """
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.post(
                f"{MEMORY_SERVICE_URL}/api/memory/monitor-events/{memory_data.get('node_id', 'node-2')}",
                json=memory_data
            )
            
            if response.status_code == 200:
                return {"saved": True, "message": "Saved to Monitor Agent memory"}
            else:
                return {"saved": False, "message": f"Failed to save: {response.status_code}"}
    except Exception as e:
        logger.error(f"Error saving to memory: {e}")
        return {"saved": False, "message": str(e)}

@app.get("/api/project/git-changes")
async def get_git_changes(limit: int = 20):
    """
    –û—Ç—Ä–∏–º–∞—Ç–∏ –æ—Å—Ç–∞–Ω–Ω—ñ git –∫–æ–º—ñ—Ç–∏ —Ç–∞ –∑–º—ñ–Ω–∏ —Ñ–∞–π–ª—ñ–≤
    TODO: –Ü–Ω—Ç–µ–≥—Ä—É–≤–∞—Ç–∏ –∑ git hooks –∞–±–æ file watchers –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è
    """
    try:
        # –ü–æ–∫–∏ —â–æ –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π –º–∞—Å–∏–≤
        # –í –º–∞–π–±—É—Ç–Ω—å–æ–º—É —Ç—É—Ç –±—É–¥–µ —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ git hooks –∞–±–æ file watchers
        return {"changes": []}
    except Exception as e:
        logger.error(f"Error fetching git changes: {e}")
        return {"changes": []}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=9500)

