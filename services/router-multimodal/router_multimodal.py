"""
Router Multimodal Support - –û–±—Ä–æ–±–∫–∞ images/files –¥–ª—è DAARION Router
–î–æ–¥–∞—Ç–∏ —Ü–µ–π –∫–æ–¥ –¥–æ —ñ—Å–Ω—É—é—á–æ–≥–æ Router –Ω–∞ NODE1
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import base64
import io
from PIL import Image
import logging

logger = logging.getLogger(__name__)

class ContextPayload(BaseModel):
    system_prompt: Optional[str] = None
    images: Optional[List[str]] = None  # base64 encoded images
    files: Optional[List[Dict[str, str]]] = None  # file metadata + base64 data

class RouteRequest(BaseModel):
    agent: str
    message: str
    mode: str = "chat"
    payload: Optional[Dict[str, Any]] = None

# Vision-–ø—ñ–¥—Ç—Ä–∏–º—É—é—á—ñ –∞–≥–µ–Ω—Ç–∏
VISION_AGENTS = {
    'sofia': {
        'model': 'grok-4.1',
        'provider': 'xai',
        'supports_vision': True,
        'supports_files': True
    },
    'spectra': {
        'model': 'qwen3-vl:latest',
        'provider': 'ollama',
        'supports_vision': True,
        'supports_files': False
    },
    'daarwizz': {
        'model': 'qwen3-8b',
        'provider': 'ollama',
        'supports_vision': False,
        'supports_files': True
    },
    'solarius': {
        'model': 'deepseek-r1:70b',
        'provider': 'ollama',
        'supports_vision': False,
        'supports_files': True
    }
}

def process_images(images: List[str]) -> List[Image.Image]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î base64 –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ PIL Image –æ–±'—î–∫—Ç–∏
    
    Args:
        images: List of base64 encoded images (with or without data:image/...;base64, prefix)
    
    Returns:
        List of PIL Image objects
    """
    processed = []
    
    for idx, img_data in enumerate(images):
        try:
            # –í–∏–¥–∞–ª–∏—Ç–∏ data:image/...;base64, –ø—Ä–µ—Ñ—ñ–∫—Å
            if ',' in img_data:
                img_data = img_data.split(',')[1]
            
            # –î–µ–∫–æ–¥—É–≤–∞—Ç–∏ base64
            img_bytes = base64.b64decode(img_data)
            img = Image.open(io.BytesIO(img_bytes))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ –≤ RGB —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            processed.append(img)
            logger.info(f"‚úÖ Processed image {idx + 1}: {img.size}, {img.mode}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to process image {idx + 1}: {e}")
            continue
    
    return processed

def process_files(files: List[Dict[str, str]]) -> List[Dict[str, Any]]:
    """
    –û–±—Ä–æ–±–ª—è—î —Ñ–∞–π–ª–∏ (PDF, TXT, MD, —Ç–æ—â–æ)
    
    Args:
        files: List of {name, type, data} dicts with base64 encoded data
    
    Returns:
        List of processed files with metadata
    """
    processed = []
    
    for idx, file_data in enumerate(files):
        try:
            name = file_data.get('name', f'file_{idx + 1}')
            file_type = file_data.get('type', 'application/octet-stream')
            data = file_data.get('data', '')
            
            # –í–∏–¥–∞–ª–∏—Ç–∏ data:...;base64, –ø—Ä–µ—Ñ—ñ–∫—Å
            if ',' in data:
                data = data.split(',')[1]
            
            # –î–µ–∫–æ–¥—É–≤–∞—Ç–∏ base64
            file_bytes = base64.b64decode(data)
            
            # –°–ø—Ä–æ–±—É–≤–∞—Ç–∏ –≤–∏—Ç—è–≥—Ç–∏ —Ç–µ–∫—Å—Ç –∑ —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ —Ñ–∞–π–ª—ñ–≤
            text_content = None
            if file_type.startswith('text/') or name.endswith(('.txt', '.md', '.json')):
                try:
                    text_content = file_bytes.decode('utf-8')
                except:
                    text_content = file_bytes.decode('latin-1')
            
            processed.append({
                'name': name,
                'type': file_type,
                'content': file_bytes,
                'text': text_content,
                'size': len(file_bytes)
            })
            
            logger.info(f"‚úÖ Processed file {idx + 1}: {name} ({len(file_bytes)} bytes)")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to process file {idx + 1}: {e}")
            continue
    
    return processed

def img_to_base64(img: Image.Image) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î PIL Image –≤ base64 string
    
    Args:
        img: PIL Image object
    
    Returns:
        base64 encoded string
    """
    buffered = io.BytesIO()
    img.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

async def route_multimodal(request: RouteRequest) -> Dict[str, Any]:
    """
    –û–±—Ä–æ–±–ª—è—î multimodal –∑–∞–ø–∏—Ç–∏ –∑ images/files
    
    –î–æ–¥–∞—Ç–∏ —Ü—é –ª–æ–≥—ñ–∫—É –≤ —ñ—Å–Ω—É—é—á–∏–π /route endpoint
    """
    try:
        # –û—Ç—Ä–∏–º–∞—Ç–∏ payload
        payload = request.payload or {}
        context = payload.get('context', {})
        
        # –í–∏–∑–Ω–∞—á–∏—Ç–∏ –∞–≥–µ–Ω—Ç–∞
        agent_id = request.agent
        agent_config = VISION_AGENTS.get(agent_id)
        
        if not agent_config:
            # –ê–≥–µ–Ω—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∏–π –≤ –º–∞–ø–ø—ñ–Ω–≥—É - –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ default
            agent_config = {
                'model': 'qwen3-8b',
                'provider': 'ollama',
                'supports_vision': False,
                'supports_files': False
            }
        
        # –û–±—Ä–æ–±–∏—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (—è–∫—â–æ —î)
        images = None
        if context.get('images'):
            images = process_images(context['images'])
            logger.info(f"üì∑ Processed {len(images)} images")
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –∞–≥–µ–Ω—Ç –ø—ñ–¥—Ç—Ä–∏–º—É—î vision
            if not agent_config['supports_vision']:
                return {
                    "error": f"–ê–≥–µ–Ω—Ç {agent_id} –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î –æ–±—Ä–æ–±–∫—É –∑–æ–±—Ä–∞–∂–µ–Ω—å",
                    "suggestion": "–°–ø—Ä–æ–±—É–π—Ç–µ sofia –∞–±–æ spectra –¥–ª—è vision tasks",
                    "available_vision_agents": [
                        k for k, v in VISION_AGENTS.items() if v['supports_vision']
                    ]
                }
        
        # –û–±—Ä–æ–±–∏—Ç–∏ —Ñ–∞–π–ª–∏ (—è–∫—â–æ —î)
        files = None
        if context.get('files'):
            files = process_files(context['files'])
            logger.info(f"üìé Processed {len(files)} files")
            
            if not agent_config['supports_files']:
                logger.warning(f"‚ö†Ô∏è Agent {agent_id} may not support files properly")
        
        # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –∑–∞–ø–∏—Ç –¥–æ LLM
        llm_request = {
            "model": agent_config['model'],
            "provider": agent_config['provider'],
            "messages": [
                {
                    "role": "system",
                    "content": context.get('system_prompt', '')
                },
                {
                    "role": "user",
                    "content": request.message
                }
            ]
        }
        
        # –î–æ–¥–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–æ –∑–∞–ø–∏—Ç—É (–¥–ª—è vision –º–æ–¥–µ–ª–µ–π)
        if images and agent_config['supports_vision']:
            if agent_config['provider'] == 'ollama':
                # Ollama Qwen3-VL format
                llm_request['images'] = [img_to_base64(img) for img in images]
            elif agent_config['provider'] == 'xai':
                # xAI grok-4.1 format
                # TODO: –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è grok-4.1
                llm_request['images'] = [img_to_base64(img) for img in images]
        
        # –î–æ–¥–∞—Ç–∏ —Ñ–∞–π–ª–∏ —è–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if files:
            files_context = "\n\n" + "="*50 + "\n"
            files_context += "üìé –ü—Ä–∏–∫—Ä—ñ–ø–ª–µ–Ω—ñ —Ñ–∞–π–ª–∏:\n\n"
            
            for f in files:
                files_context += f"**{f['name']}** ({f['size']} bytes, {f['type']})\n"
                if f['text']:
                    # –Ø–∫—â–æ —Ñ–∞–π–ª –º—ñ—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç - –¥–æ–¥–∞—Ç–∏ –π–æ–≥–æ
                    files_context += f"```\n{f['text'][:2000]}\n```\n"
                    if len(f['text']) > 2000:
                        files_context += f"... (—â–µ {len(f['text']) - 2000} —Å–∏–º–≤–æ–ª—ñ–≤)\n"
                files_context += "\n"
            
            files_context += "="*50
            
            # –î–æ–¥–∞—Ç–∏ –¥–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
            llm_request['messages'][-1]['content'] += files_context
        
        # –í–∏–∫–ª–∏–∫–∞—Ç–∏ LLM (—ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ —ñ—Å–Ω—É—é—á–æ—é –ª–æ–≥—ñ–∫–æ—é Router)
        # TODO: –ó–∞–º—ñ–Ω–∏—Ç–∏ —Ü–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏–π –≤–∏–∫–ª–∏–∫ LLM
        response_text = await call_llm(llm_request)
        
        return {
            "data": {
                "text": response_text,
                "model": agent_config['model'],
                "provider": agent_config['provider']
            },
            "metadata": {
                "agent": agent_id,
                "has_images": bool(images),
                "has_files": bool(files),
                "images_count": len(images) if images else 0,
                "files_count": len(files) if files else 0
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå Multimodal routing error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

async def call_llm(request: Dict[str, Any]) -> str:
    """
    –í–∏–∫–ª–∏–∫–∞—î LLM (Ollama –∞–±–æ xAI)
    
    –Ü–Ω—Ç–µ–≥—Ä—É–≤–∞—Ç–∏ –∑ —ñ—Å–Ω—É—é—á–æ—é –ª–æ–≥—ñ–∫–æ—é Router
    """
    # TODO: –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –≤–∏–∫–ª–∏–∫ LLM
    # –¶–µ –º–∞—î –±—É—Ç–∏ —ñ–Ω—Ç–µ–≥—Ä–æ–≤–∞–Ω–æ –∑ —ñ—Å–Ω—É—é—á–æ—é –ª–æ–≥—ñ–∫–æ—é Router
    pass

# –ü—Ä–∏–∫–ª–∞–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤ FastAPI
def add_multimodal_to_router(app: FastAPI):
    """
    –î–æ–¥–∞—î multimodal endpoints –¥–æ —ñ—Å–Ω—É—é—á–æ–≥–æ Router
    """
    
    @app.post("/route")
    async def route(request: RouteRequest):
        """
        –û–Ω–æ–≤–ª–µ–Ω–∏–π /route endpoint –∑ multimodal –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é
        """
        return await route_multimodal(request)
    
    @app.get("/agents/vision")
    async def get_vision_agents():
        """
        –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –∞–≥–µ–Ω—Ç—ñ–≤ –∑ vision –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é
        """
        return {
            "vision_agents": [
                {
                    "id": k,
                    "model": v['model'],
                    "provider": v['provider'],
                    "supports_vision": v['supports_vision'],
                    "supports_files": v['supports_files']
                }
                for k, v in VISION_AGENTS.items()
                if v['supports_vision']
            ]
        }

